「学习内容总结自[ udacity ](http://cn.udacity.com/course/deep-learning-nanodegree-foundation--nd101-cn/)和[ coursera ](https://www.coursera.org/courses)的深度学习课程，截图来自 udacity 课件」

### 一.模型训练

#### 1.为模型创建测试集

建立好一个模型之后我们要怎么评估它的好坏以及泛化的能力（由具体的，个别的扩大为一般的能力）呢？这时候就需要引进**测试集**的概念。
![](http://upload-images.jianshu.io/upload_images/2759738-c8d0bb681a914de3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
如上图，空心代表测试集数据，实心代表训练集数据。我们对两个模型分别进行了不同的拟合，那么两个模型哪个效果比较好呢？从拟合角度来看两者的拟合效果差不多。但是引入测试集后，从测试集角度观察结果（如下图），左边模型有一个错误，而右边模型有两个错误。所以通过测试，左边的模型比较好。
![](http://upload-images.jianshu.io/upload_images/2759738-150ebf67d6959d9e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


我们使用sklearn这个库，很容易实现：
```
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(x,
                                                 y,
                                                 test_size = 0.25)
                                                 #0.25表示从总数据中取25%作为测试集
                                                                        
```
>还有一条非常重要的黄金法则我们不能违背：**不能用测试集来训练**

一般做预测分析时，会将数据分为两大部分。一部分是训练数据集，用于构建模型，一部分是测试数据集，用于检验模型的性能。但是，有时候在模型的构建过程中也需要检验模型，辅助优化模型，调整模型参数，这时候就会引入验证数据集，验证集有时候也称为开发集(Dev set)。有一点要注意的是，**要确保验证集和测试集来自同一分布**。
>- Training set: A set of examples used for learning, which is to fit the parameters [i.e., weights] of the classifier. 
>- Validation set: A set of examples used to tune the parameters [i.e., architecture, not weights] of a classifier, for example to choose the number of hidden units in a neural network. 
>- Test set: A set of examples used only to assess the performance [generalization] of a fully specified classifier. 

![](http://upload-images.jianshu.io/upload_images/2759738-d64e2d509ec604ea.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

在数据集较小的时候，训练集，验证集和测试集的大概比例划分为：60%，20%和20%；但在数据集非常庞大的时候，训练集，验证集和测试集的大概比例划分为：98%，1%和1%。

#### 2.欠拟合与过拟合

在模型训练的过程中，会出现欠拟合和过拟合的现象。下面仍然以猫图片识别的例子来说明：

- 偏差和方差

  在猫图片辨别的例子中，按照人的标准，误差接近于0。在下面这张图里，人的水平和训练集的性能之间的差距可以称为可避免误差(Avoidable bias)，训练集和验证集之间的差距称为方差(variance)

![](http://upload-images.jianshu.io/upload_images/2759738-c4a465b90d8551b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 欠拟合-高偏差

  如果在猫图片辨别的例子中，在训练集上表现出的误差为15%，在验证集上表现出的误差为16%。这时候称训练集**欠拟合**，因为训练集表现出的能力与人相差比较大，而训练集和验证集的相差较小，存在高偏差。
  欠拟合体现出模型没有很好地拟合数据，但是和理想水平之间的差距是可以避免的，距离达到理想水平还需要做出一些优化。

- 过拟合-高方差

  如果在猫图片辨别的例子中，在训练集上表现出的误差为1%，在验证集上表现出的误差为16%。这时候称验证集**过拟合**，因为训练集表现出的能力与人相差很小，但验证集与人的表现相差很大，存在高方差。
  过拟合体现出模型过度地拟合了数据，只充分学习到给予训练的数据集的特征，所以在其他数据集上就没能发挥出理想水平。

  

#### 3.对于欠拟合的优化

  

  出现欠拟合的情况，可以用下面的方法来优化：

- 建立一个更大的网络

- 训练的更久，采用优化算法--momentum，Adam，RMSprop
  优化算法可以查看[这篇笔记](https://www.jianshu.com/p/53870e16b326)

- 神经网络结构的研究--CNN,RNN

  

  
#### 4.对于过拟合的优化

  

  出现过拟合的情况，可以用下面的方法来优化：

- 准备更多的数据

  训练集不够多的情况下，可以在已有的数据集上，利用数据扩展的方法把图片中的内容，经过裁剪，平移，翻转等操作来增加训练数据集。这样还能避免数据来自不同的分布。

- Early stopping

  为了避免神经网络过拟合，可以采取早期停止的做法，在模型达到最高性能的时候就停止训练。
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-d6e2227c792574f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- L2正则化

  L2正则化也是一个很好的防止过拟合的方法。一般地，在损失函数后面会加上权重w的范数的平方再乘以一个小的常数β，这样做能够惩罚过大的权重。
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-53a3c7a5632b30f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

  **L2正则化能够减少过拟合的原因**：

  对于整个深度神经网络有：
  成本函数：
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-919d30df03a4c8e6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  
  更新权重:
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-a388bccc06c98158.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  
  *(from backprop表示从反向传播求偏导的公式，此处简略表示)*
  
  可以从上面的式子中看出，w<sup>[L]</sup>的系数是小于1的，表示每次更新权重都是衰减的，所以L2正则化也称为“权重衰减”。
  解释1):
  直观的理解就是，当β设置的足够大，权重矩阵w会被设置为接近于0，即把多隐藏单元的权重设置为0，于是就消除了这些隐藏单元的影响，复杂的网络就会简化成简单的网络，使网络存在高偏差，但β一定会存在一个中间值使得网络拟合的刚刚好。
  解释2):
  也可以从上面的式子中看出，β增大时，w<sup>[L]</sup>是减小的。以下面的tanh激活函数的图像来说明，w<sup>[L]</sup>减小，z<sup>[L]</sup>也相对减小，进而使取值集中在tanh激活函数的线性区域，这样每层网络就都接近于线性，这样的线性网络不适用于非常复杂的决策，不会出现过度拟合数据集的非线性边界。所以就能够减少过拟合。
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-994212b7990624ed.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)



- Dropout

  Dropout--随机失活，是一种较为疯狂的做法，运作机制就是一层层的遍历神经网络，每层网络中的某些神经元按照一定的概率随机的被抛弃。Dropout可以使神经网络相对变得更小，这与正则化的效果是一样。Dropout也使得神经元不依赖任何输入的特征，不会使网络只学习到某些特征，而忽略其他特征，因为每个特征都会被随机的删除抛弃。

  
### 二.模型评估

#### 1.使用混淆矩阵评估模型

  
  如下图所示，我们以去医院就诊为例（生病为阳性，健康为阴性）。当一个病人被确诊为生病时，我们称之为True Positive（真阳性）;当一个健康的人被认为健康时，我们称之为True Negative（真阴性）；当一个病人被误诊为健康时，我们称之为False Negative（假阴性）；当一个健康的人被误诊为生病时，我们称之为False Positive（假阳性）。这就是一个典型的**混淆矩阵**，用来描述模型性能的一张表。
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-2aedfbda0e38dc66.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  
  假设在一个模型中，我们共有10000名患者，其中有1000名患者被确诊，我们标进True Positive这一格；有200名患者被误诊为健康，我们标进False Negative这一格；有800名健康的人被误诊为患病，我们标进False Positive；有1000名健康的人被认为健康，我们标进True Negative这一格。
  
  ![](http://upload-images.jianshu.io/upload_images/2759738-a85202468a61a3e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

#### 2.使用准确率，查准率和查全率来评估模型



+ 准确率Accuracy

  准确率(Accuracy)也是评估模型性能的一个指标。继续以上面10000名患者诊断为例。我们可以计算出准确率为：(1000+8000)/10000*100%=90%，计算公式为：(True Positive样本数+True Negative样本数)/总样本数

![](http://upload-images.jianshu.io/upload_images/2759738-1be952a3764c24c6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 查准率Precision 

  查准率指的是计算阳性样本中真阳性的比率。上面例子的查准率为：1000/(1000+800)x100%=55.56%，计算公式为：True Positive样本数/总阳性样本数。

- 查全率Recall

  查全率指的是真正患病的样本数在患病总样本数中的比率，即1000/(1000+200)=83.33%,计算公式为：True Positive样本数/(True Positive样本数+True Negative样本数)

- 总结

  Accuracy = (预测正确的样本数)/(总样本数)=(TP+TN)/(TP+TN+FP+FN)
  Precision = (预测为阳性且正确预测的样本数)/(所有预测为阳性的样本数) = TP/(TP+FP)
  Recall = (预测为阳性且正确预测的样本数)/(所有真实情况为阳性的样本数) = TP/(TP+FN)

